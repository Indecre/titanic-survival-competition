# ğŸš¢ Titanic Survival Prediction

This project predicts passenger survival on the Titanic using machine learning. It was built as a beginner-level classification task for the [Kaggle Titanic Competition](https://www.kaggle.com/competitions/titanic).

---

## ğŸ“Š Overview

The Titanic dataset provides details about passengers such as age, sex, ticket class, and more. Using this information, the goal is to predict whether a passenger survived the disaster.

---

## ğŸ§  Machine Learning Workflow

1. **Data Cleaning**
   - Filled missing `Age` and `Fare` values with median.
   - Normalized categorical columns (e.g. `Embarked`).

2. **Feature Engineering**
   - Combined `SibSp` and `Parch` into a new `family` feature.
   - Categorized passengers into `family_group` ("Alone", "Medium", "Large").

3. **Encoding**
   - Used `pd.get_dummies()` to one-hot encode categorical variables.

4. **Modeling**
   - Trained a `RandomForestClassifier` using `scikit-learn`.
   - Achieved predictions on test data aligned with training columns.

5. **Submission**
   - Created a `submission.csv` file as per Kaggle format.

---

## ğŸ“ Files

- `train.csv` â€“ Training dataset (from Kaggle)
- `test.csv` â€“ Test dataset (from Kaggle)
- `titanic.ipynb` â€“ Jupyter notebook with all preprocessing, training, and prediction code
- `submission.csv` â€“ Final submission file for Kaggle

---

## ğŸ§° Tools & Libraries

- Python 3
- pandas
- NumPy
- scikit-learn
- Jupyter Notebook

---

## ğŸ“¦ How to Run

1. Clone the repo
2. Install dependencies (optional: create a virtual environment)
3. Open `titanic.ipynb` and run all cells
4. Upload `submission.csv` to [Kaggle Titanic competition](https://www.kaggle.com/competitions/titanic)

---

## ğŸ“ˆ Future Work

- Try other models: Logistic Regression, XGBoost, SVM
- Hyperparameter tuning
- Cross-validation
- Model explainability using SHAP or feature importance plots

---

## ğŸ‘¤ Author

Aryan Shukla  
[GitHub](https://github.com/Indecre) â€¢ [Email](mailto:aryanshukla20102006@gmail.com)

